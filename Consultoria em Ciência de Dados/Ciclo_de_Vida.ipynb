{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0c830350-7e50-4a78-861f-b86ecfed26d9",
      "metadata": {
        "id": "0c830350-7e50-4a78-861f-b86ecfed26d9"
      },
      "source": [
        "Análise Inicial dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1ecd3190-476b-40a7-8fd8-3a47cc29d3a8",
      "metadata": {
        "id": "1ecd3190-476b-40a7-8fd8-3a47cc29d3a8"
      },
      "outputs": [],
      "source": [
        "# importa biblioteca pandas\n",
        "import pandas as pd\n",
        "# importa biblioteca numpy\n",
        "import numpy as np\n",
        "# importa biblioteca statsmodels\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# local do arquivo\n",
        "Caminho='/content/Credito.xlsx'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "750fc13c-9da6-422d-b063-cd70f0009ba2",
      "metadata": {
        "id": "750fc13c-9da6-422d-b063-cd70f0009ba2"
      },
      "outputs": [],
      "source": [
        "#Traz o arquivo para o Python\n",
        "df=pd.read_excel(Caminho)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b694324f-74b5-451c-b62e-4b7e7b3ab595",
      "metadata": {
        "id": "b694324f-74b5-451c-b62e-4b7e7b3ab595"
      },
      "outputs": [],
      "source": [
        "#Tabelas de Frequencia para variáveis binárias/nominais\n",
        "\n",
        "# Lista de variáveis para as quais você deseja calcular tabelas de frequência\n",
        "variaveis = [  'qtd_com',  'tipo_cre','tipo']\n",
        "\n",
        "# Calcular tabelas de frequência para cada variável\n",
        "for variavel in variaveis:\n",
        "    freq_table = df[variavel].value_counts()\n",
        "    percentual = (df[variavel].value_counts(normalize=True) * 100).round(2)\n",
        "\n",
        "    # Concatenar as tabelas de frequência e percentual\n",
        "    freq_table = pd.concat([freq_table, percentual], axis=1)\n",
        "    freq_table.columns = ['Frequência', 'Percentual (%)']\n",
        "\n",
        "    print(\"Tabela de Frequência para '{}':\\n\".format(variavel), freq_table)\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rc34Vi15E-N"
      },
      "id": "1rc34Vi15E-N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e696bd16-2112-439b-abf4-8eedd5234289",
      "metadata": {
        "id": "e696bd16-2112-439b-abf4-8eedd5234289"
      },
      "outputs": [],
      "source": [
        "#Análises descritivas variáveis quantitativas\n",
        "\n",
        "def analise_descritiva(df, variaveis):\n",
        "    # Estatísticas descritivas para variáveis numéricas\n",
        "    desc_stats_numericas = df[variaveis].describe()\n",
        "\n",
        "    return desc_stats_numericas\n",
        "\n",
        "def main():\n",
        "    # Variáveis para análise descritiva\n",
        "    variaveis_para_analise = ['idade',  'tempo_em', 'sal_cli', 'tempo_res', 'qtd_parc', 'vlr_cpr', 'vlr_parc']\n",
        "\n",
        "    # Realizar análise descritiva\n",
        "    desc_stats_numericas = analise_descritiva(df, variaveis_para_analise)\n",
        "\n",
        "    # Imprimir resultados\n",
        "    print(\"Estatísticas Descritivas para Variáveis Numéricas:\")\n",
        "    print(desc_stats_numericas)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e235881d-0135-45eb-89d4-fefa60545f56",
      "metadata": {
        "id": "e235881d-0135-45eb-89d4-fefa60545f56"
      },
      "outputs": [],
      "source": [
        "#Como o menor salário é 0.01, vamos fazer um ajuste e colocar um valor mais factível como mínimo por exemplo R$ 250\n",
        "\n",
        "df['sal_cli'] = df['sal_cli'].apply(lambda x: 250 if pd.isnull(x) or x < 250 else x)\n",
        "\n",
        "# Criar nova variável dividindo 'vlr_parc' por 'sal_cli' - Comprometimento\n",
        "df['comprom'] = df['vlr_parc'] / df['sal_cli']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff993ce6-d185-4967-907d-3c28232ff69e",
      "metadata": {
        "id": "ff993ce6-d185-4967-907d-3c28232ff69e"
      },
      "outputs": [],
      "source": [
        "#amostra estratificada\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def criar_amostra_estratificada(df, variavel_resposta, tamanho_amostra, variaveis_preditoras):\n",
        "    X = df[variaveis_preditoras]\n",
        "    y = df[variavel_resposta]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tamanho_amostra, stratify=y, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Definição das variáveis preditoras para análise\n",
        "variaveis_para_analise = ['idade', 'qtd_com', 'tempo_em', 'sal_cli', 'tempo_res', 'qtd_parc', 'vlr_cpr', 'vlr_parc', 'tipo_cre','comprom']\n",
        "\n",
        "# Chamada da função para criar amostra estratificada\n",
        "X_train, X_test, y_train, y_test = criar_amostra_estratificada(df, 'tipo', 0.4, variaveis_para_analise)\n",
        "\n",
        "# Imprimir informações sobre a amostra\n",
        "print(\"\\nInformações sobre a amostra estratificada:\")\n",
        "print(\"Tamanho do conjunto de treino:\", len(X_train))\n",
        "print(\"Tamanho do conjunto de teste:\", len(X_test))\n",
        "\n",
        "\n",
        "# Calcular frequência da variável 'tipo' nas amostras de treino e teste\n",
        "frequencia_tipo_treino = y_train.value_counts()\n",
        "frequencia_tipo_teste = y_test.value_counts()\n",
        "\n",
        "# Imprimir frequência da variável 'tipo'\n",
        "print(\"Frequência da variável 'tipo' no conjunto de treino:\")\n",
        "print(frequencia_tipo_treino)\n",
        "\n",
        "print(\"\\nFrequência da variável 'tipo' no conjunto de teste:\")\n",
        "print(frequencia_tipo_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1319211-2f42-4cd1-899b-dda76798bd59",
      "metadata": {
        "id": "e1319211-2f42-4cd1-899b-dda76798bd59"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Criar pipeline com modelo de regressão logística\n",
        "pipeline = Pipeline([\n",
        "    ('logistic_regression', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Treinar o modelo no pipeline usando os dados de treino\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Coeficientes do modelo de regressão logística\n",
        "coeficientes = pipeline.named_steps['logistic_regression'].coef_[0]\n",
        "\n",
        "# Intercepto do modelo de regressão logística\n",
        "intercepto = pipeline.named_steps['logistic_regression'].intercept_\n",
        "\n",
        "# Nomes das variáveis preditoras\n",
        "nomes_variaveis = X_train.columns.tolist()\n",
        "\n",
        "# Imprimir coeficientes associados a cada variável\n",
        "print(\"Coeficientes do modelo:\")\n",
        "for nome_variavel, coeficiente in zip(nomes_variaveis, coeficientes):\n",
        "    print(nome_variavel, \":\", coeficiente)\n",
        "\n",
        "# Imprimir intercepto do modelo\n",
        "print(\"\\nIntercepto do modelo:\", intercepto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc14488f-f2d5-4132-9bd4-e9e7bd1475ff",
      "metadata": {
        "id": "cc14488f-f2d5-4132-9bd4-e9e7bd1475ff"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Prever as probabilidades das classes positivas para os dados de teste\n",
        "probabilidades_positivas = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular KS\n",
        "fpr, tpr, thresholds = roc_curve(y_test, probabilidades_positivas)\n",
        "ks = max(tpr - fpr)\n",
        "\n",
        "# Calcular AUC (área sob a curva ROC)\n",
        "auc = roc_auc_score(y_test, probabilidades_positivas)\n",
        "\n",
        "# Calcular matriz de confusão\n",
        "previsoes = pipeline.predict(X_test)\n",
        "matriz_confusao = confusion_matrix(y_test, previsoes)\n",
        "\n",
        "# Calcular acurácia total\n",
        "acuracia_total = pipeline.score(X_test, y_test)\n",
        "\n",
        "# Imprimir métricas de avaliação\n",
        "print(\"KS:\", ks)\n",
        "print(\"AUC:\", auc)\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(matriz_confusao)\n",
        "print(\"Acurácia Total:\", acuracia_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64c3f0cf-009a-4f84-bfce-6d0a30e5076e",
      "metadata": {
        "id": "64c3f0cf-009a-4f84-bfce-6d0a30e5076e"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Criar modelo de redes neurais\n",
        "modelo_rede_neural = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
        "\n",
        "# Treinar o modelo nos dados de treino\n",
        "modelo_rede_neural.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar o modelo nos dados de teste\n",
        "acuracia_teste_rede_neural = modelo_rede_neural.score(X_test, y_test)\n",
        "\n",
        "# Imprimir acurácia do modelo nos dados de teste\n",
        "print(\"Acurácia do modelo de redes neurais nos dados de teste:\", acuracia_teste_rede_neural)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46aa1955-c98d-40e5-bf50-93190d74fc31",
      "metadata": {
        "id": "46aa1955-c98d-40e5-bf50-93190d74fc31"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Prever as probabilidades das classes positivas para os dados de teste\n",
        "probabilidades_positivas_rede_neural = modelo_rede_neural.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular KS\n",
        "fpr_rede_neural, tpr_rede_neural, thresholds_rede_neural = roc_curve(y_test, probabilidades_positivas_rede_neural)\n",
        "ks_rede_neural = max(tpr_rede_neural - fpr_rede_neural)\n",
        "\n",
        "# Calcular AUC (área sob a curva ROC)\n",
        "auc_rede_neural = roc_auc_score(y_test, probabilidades_positivas_rede_neural)\n",
        "\n",
        "# Calcular matriz de confusão\n",
        "previsoes_rede_neural = modelo_rede_neural.predict(X_test)\n",
        "matriz_confusao_rede_neural = confusion_matrix(y_test, previsoes_rede_neural)\n",
        "\n",
        "# Calcular acurácia total\n",
        "acuracia_total_rede_neural = modelo_rede_neural.score(X_test, y_test)\n",
        "\n",
        "# Imprimir métricas de avaliação para o modelo de rede neural\n",
        "print(\"KS (Rede Neural):\", ks_rede_neural)\n",
        "print(\"AUC (Rede Neural):\", auc_rede_neural)\n",
        "print(\"Matriz de Confusão (Rede Neural):\")\n",
        "print(matriz_confusao_rede_neural)\n",
        "print(\"Acurácia Total (Rede Neural):\", acuracia_total_rede_neural)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a471ab04-9c1a-465e-99ac-b554f0f1bda9",
      "metadata": {
        "id": "a471ab04-9c1a-465e-99ac-b554f0f1bda9"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Criar modelo de árvore de decisão\n",
        "modelo_arvore = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Treinar o modelo nos dados de treino\n",
        "modelo_arvore.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar o modelo nos dados de teste\n",
        "acuracia_teste_arvore = modelo_arvore.score(X_test, y_test)\n",
        "\n",
        "# Imprimir acurácia do modelo nos dados de teste\n",
        "print(\"Acurácia do modelo de árvore de decisão nos dados de teste:\", acuracia_teste_arvore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3e02477-9f31-4f01-af78-56b87a9a96fb",
      "metadata": {
        "id": "c3e02477-9f31-4f01-af78-56b87a9a96fb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Prever as probabilidades das classes positivas para os dados de teste\n",
        "probabilidades_positivas_arvore = modelo_arvore.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular KS\n",
        "fpr_arvore, tpr_arvore, thresholds_arvore = roc_curve(y_test, probabilidades_positivas_arvore)\n",
        "ks_arvore = max(tpr_arvore - fpr_arvore)\n",
        "\n",
        "# Calcular AUC (área sob a curva ROC)\n",
        "auc_arvore = roc_auc_score(y_test, probabilidades_positivas_arvore)\n",
        "\n",
        "# Calcular matriz de confusão\n",
        "previsoes_arvore = modelo_arvore.predict(X_test)\n",
        "matriz_confusao_arvore = confusion_matrix(y_test, previsoes_arvore)\n",
        "\n",
        "# Calcular acurácia total\n",
        "acuracia_total_arvore = modelo_arvore.score(X_test, y_test)\n",
        "\n",
        "# Imprimir métricas de avaliação para o modelo de árvore de decisão\n",
        "print(\"KS (Árvore de Decisão):\", ks_arvore)\n",
        "print(\"AUC (Árvore de Decisão):\", auc_arvore)\n",
        "print(\"Matriz de Confusão (Árvore de Decisão):\")\n",
        "print(matriz_confusao_arvore)\n",
        "print(\"Acurácia Total (Árvore de Decisão):\", acuracia_total_arvore)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f58236-8eaf-43eb-8a83-958c09b5a694",
      "metadata": {
        "id": "05f58236-8eaf-43eb-8a83-958c09b5a694"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Criar modelo Random Forest\n",
        "modelo_random_forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Treinar o modelo nos dados de treino\n",
        "modelo_random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar o modelo nos dados de teste\n",
        "acuracia_teste_random_forest = modelo_random_forest.score(X_test, y_test)\n",
        "\n",
        "# Prever as probabilidades das classes positivas para os dados de teste\n",
        "probabilidades_positivas_random_forest = modelo_random_forest.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular KS\n",
        "fpr_random_forest, tpr_random_forest, thresholds_random_forest = roc_curve(y_test, probabilidades_positivas_random_forest)\n",
        "ks_random_forest = max(tpr_random_forest - fpr_random_forest)\n",
        "\n",
        "# Calcular AUC (área sob a curva ROC)\n",
        "auc_random_forest = roc_auc_score(y_test, probabilidades_positivas_random_forest)\n",
        "\n",
        "# Calcular matriz de confusão\n",
        "previsoes_random_forest = modelo_random_forest.predict(X_test)\n",
        "matriz_confusao_random_forest = confusion_matrix(y_test, previsoes_random_forest)\n",
        "\n",
        "# Calcular acurácia total\n",
        "acuracia_total_random_forest = modelo_random_forest.score(X_test, y_test)\n",
        "\n",
        "# Imprimir acurácia do modelo nos dados de teste\n",
        "print(\"Acurácia do modelo Random Forest nos dados de teste:\", acuracia_teste_random_forest)\n",
        "print(\"KS (Random Forest):\", ks_random_forest)\n",
        "print(\"AUC (Random Forest):\", auc_random_forest)\n",
        "print(\"Matriz de Confusão (Random Forest):\")\n",
        "print(matriz_confusao_random_forest)\n",
        "print(\"Acurácia Total (Random Forest):\", acuracia_total_random_forest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf969a08-202f-4f97-82fc-6042266e6a93",
      "metadata": {
        "id": "cf969a08-202f-4f97-82fc-6042266e6a93"
      },
      "source": [
        "Escorando uma base com o melhor modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d65c797-3790-4afe-a82a-9e3279e80650",
      "metadata": {
        "id": "2d65c797-3790-4afe-a82a-9e3279e80650"
      },
      "outputs": [],
      "source": [
        "# Carregar a nova base de clientes\n",
        "caminho_nova_base = 'C:/_Academico/PUC/202401/CDIA2/Credito_escorar.xlsx'\n",
        "nova_base = pd.read_excel(caminho_nova_base)\n",
        "\n",
        "# Salvar os IDs dos clientes separadamente\n",
        "ids_clientes = nova_base['id']\n",
        "\n",
        "# Remover as colunas irrelevantes ('id', 'tipo') e reordenar as colunas para corresponder à ordem do modelo\n",
        "colunas_modelo = ['idade', 'qtd_com', 'tempo_em', 'sal_cli', 'tempo_res', 'qtd_parc', 'vlr_cpr', 'vlr_parc', 'tipo_cre']\n",
        "nova_base = nova_base[colunas_modelo]\n",
        "\n",
        "# Aplicar as transformações necessárias nas outras colunas\n",
        "nova_base['sal_cli'] = nova_base['sal_cli'].apply(lambda x: 250 if pd.isnull(x) or x < 250 else x)\n",
        "nova_base['comprom'] = nova_base['vlr_parc'] / nova_base['sal_cli']\n",
        "\n",
        "# Fazer previsões e obter probabilidades na nova base de clientes com as transformações aplicadas\n",
        "previsoes_probabilidades_nova_base = pipeline.predict_proba(nova_base)\n",
        "\n",
        "# Extrair as previsões e as probabilidades associadas\n",
        "probabilidades_nova_base = previsoes_probabilidades_nova_base[:, 1]  # Probabilidades para a classe positiva (ou 1)\n",
        "\n",
        "# Adicionar as previsões e as probabilidades como novas colunas na nova base de clientes\n",
        "nova_base['probabilidade'] = probabilidades_nova_base\n",
        "\n",
        "# Juntar os IDs dos clientes de volta à nova base de clientes\n",
        "nova_base['id'] = ids_clientes\n",
        "\n",
        "# Salvar a nova base de clientes com as previsões\n",
        "caminho_saida = 'C:/_Academico/PUC/202401/CDIA2/Credito_escorada.xlsx'\n",
        "nova_base.to_excel(caminho_saida, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9b3514-8ddc-4448-b78c-a1bab33137cf",
      "metadata": {
        "id": "9f9b3514-8ddc-4448-b78c-a1bab33137cf"
      },
      "outputs": [],
      "source": [
        "nova_base = pd.read_excel(caminho_nova_base)\n",
        "\n",
        "# Salvar os IDs dos clientes separadamente\n",
        "ids_clientes = nova_base['id']\n",
        "\n",
        "# Remover as colunas irrelevantes ('id', 'tipo') e reordenar as colunas para corresponder à ordem do modelo\n",
        "colunas_modelo = ['idade',  'qtd_com', 'tempo_em', 'sal_cli', 'tempo_res', 'qtd_parc', 'vlr_cpr', 'vlr_parc', 'tipo_cre']\n",
        "nova_base = nova_base[colunas_modelo]\n",
        "\n",
        "# Aplicar as transformações necessárias nas outras colunas\n",
        "nova_base['sal_cli'] = nova_base['sal_cli'].apply(lambda x: 250 if pd.isnull(x) or x < 250 else x)\n",
        "nova_base['comprom'] = nova_base['vlr_parc'] / nova_base['sal_cli']\n",
        "\n",
        "# Fazer previsões e obter probabilidades na nova base de clientes com as transformações aplicadas\n",
        "previsoes_probabilidades_nova_base = modelo_random_forest.predict_proba(nova_base)\n",
        "\n",
        "# Extrair as previsões e as probabilidades associadas\n",
        "probabilidades_nova_base = previsoes_probabilidades_nova_base[:, 1]  # Probabilidades para a classe positiva (ou 1)\n",
        "\n",
        "# Adicionar as previsões e as probabilidades como novas colunas na nova base de clientes\n",
        "nova_base['probabilidade'] = probabilidades_nova_base\n",
        "\n",
        "# Juntar os IDs dos clientes de volta à nova base de clientes\n",
        "nova_base['id'] = ids_clientes\n",
        "\n",
        "\n",
        "# Salvar a nova base de clientes com as previsões\n",
        "caminho_saida = '/content/Credito_escorar.xlsx'\n",
        "nova_base.to_excel(caminho_saida, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf192b99-8c2c-4fe1-a08e-539d66cddbf0",
      "metadata": {
        "id": "cf192b99-8c2c-4fe1-a08e-539d66cddbf0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}