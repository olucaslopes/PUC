{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c830350-7e50-4a78-861f-b86ecfed26d9",
   "metadata": {
    "id": "0c830350-7e50-4a78-861f-b86ecfed26d9"
   },
   "source": [
    "Análise Inicial dos dados"
   ]
  },
  {
   "cell_type": "code",
   "id": "1ecd3190-476b-40a7-8fd8-3a47cc29d3a8",
   "metadata": {
    "id": "1ecd3190-476b-40a7-8fd8-3a47cc29d3a8",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:13.355695Z",
     "start_time": "2024-04-17T12:40:13.336448Z"
    }
   },
   "source": [
    "# importa biblioteca pandas\n",
    "import pandas as pd\n",
    "# importa biblioteca numpy\n",
    "import numpy as np\n",
    "# importa biblioteca statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# local do arquivo\n",
    "Caminho='Credito.xlsx'"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "KS >= 30\n",
    "AUC >= 1.25 x acaso\n",
    "ROC >= 60"
   ],
   "id": "6ec6d334e9cc406d"
  },
  {
   "cell_type": "code",
   "id": "750fc13c-9da6-422d-b063-cd70f0009ba2",
   "metadata": {
    "id": "750fc13c-9da6-422d-b063-cd70f0009ba2",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:15.907409Z",
     "start_time": "2024-04-17T12:40:13.415034Z"
    }
   },
   "source": [
    "#Traz o arquivo para o Python\n",
    "df=pd.read_excel(Caminho)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id  idade  qtd_com  tempo_em  sal_cli  tempo_res  qtd_parc  vlr_cpr  \\\n",
       "0   1     57        1       238   4096.9        322         8   2000.0   \n",
       "1   2     40        0        24    581.3        300         9    300.0   \n",
       "2   3     28        1        72    901.5        216         6    700.0   \n",
       "3   4     41        1        25   1279.0         76         8   1200.0   \n",
       "4   5     44        0       120   3000.0        132         6    600.0   \n",
       "\n",
       "   vlr_parc  tipo_cre  tipo  \n",
       "0    394.22         1     1  \n",
       "1     64.34         1     0  \n",
       "2    176.50         1     0  \n",
       "3    245.29         1     1  \n",
       "4    170.25         1     0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>idade</th>\n",
       "      <th>qtd_com</th>\n",
       "      <th>tempo_em</th>\n",
       "      <th>sal_cli</th>\n",
       "      <th>tempo_res</th>\n",
       "      <th>qtd_parc</th>\n",
       "      <th>vlr_cpr</th>\n",
       "      <th>vlr_parc</th>\n",
       "      <th>tipo_cre</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>4096.9</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>394.22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>581.3</td>\n",
       "      <td>300</td>\n",
       "      <td>9</td>\n",
       "      <td>300.0</td>\n",
       "      <td>64.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>901.5</td>\n",
       "      <td>216</td>\n",
       "      <td>6</td>\n",
       "      <td>700.0</td>\n",
       "      <td>176.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>76</td>\n",
       "      <td>8</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>245.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>132</td>\n",
       "      <td>6</td>\n",
       "      <td>600.0</td>\n",
       "      <td>170.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "b694324f-74b5-451c-b62e-4b7e7b3ab595",
   "metadata": {
    "id": "b694324f-74b5-451c-b62e-4b7e7b3ab595",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:15.931036Z",
     "start_time": "2024-04-17T12:40:15.907409Z"
    }
   },
   "source": [
    "#Tabelas de Frequencia para variáveis binárias/nominais\n",
    "\n",
    "# Lista de variáveis para as quais você deseja calcular tabelas de frequência\n",
    "variaveis = [  'qtd_com',  'tipo_cre','tipo']\n",
    "\n",
    "# Calcular tabelas de frequência para cada variável\n",
    "for variavel in variaveis:\n",
    "    freq_table = df[variavel].value_counts()\n",
    "    percentual = (df[variavel].value_counts(normalize=True) * 100).round(2)\n",
    "\n",
    "    # Concatenar as tabelas de frequência e percentual\n",
    "    freq_table = pd.concat([freq_table, percentual], axis=1)\n",
    "    freq_table.columns = ['Frequência', 'Percentual (%)']\n",
    "\n",
    "    print(\"Tabela de Frequência para '{}':\\n\".format(variavel), freq_table)\n",
    "    print(\"\\n\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela de Frequência para 'qtd_com':\n",
      "          Frequência  Percentual (%)\n",
      "qtd_com                            \n",
      "0              9852           54.73\n",
      "1              8148           45.27\n",
      "\n",
      "\n",
      "Tabela de Frequência para 'tipo_cre':\n",
      "           Frequência  Percentual (%)\n",
      "tipo_cre                            \n",
      "1              15307           85.04\n",
      "0               2693           14.96\n",
      "\n",
      "\n",
      "Tabela de Frequência para 'tipo':\n",
      "       Frequência  Percentual (%)\n",
      "tipo                            \n",
      "1           9000            50.0\n",
      "0           9000            50.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "1rc34Vi15E-N",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:15.949554Z",
     "start_time": "2024-04-17T12:40:15.931036Z"
    }
   },
   "id": "1rc34Vi15E-N",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "e696bd16-2112-439b-abf4-8eedd5234289",
   "metadata": {
    "id": "e696bd16-2112-439b-abf4-8eedd5234289",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:15.978652Z",
     "start_time": "2024-04-17T12:40:15.949554Z"
    }
   },
   "source": [
    "#Análises descritivas variáveis quantitativas\n",
    "\n",
    "def analise_descritiva(df, variaveis):\n",
    "    # Estatísticas descritivas para variáveis numéricas\n",
    "    desc_stats_numericas = df[variaveis].describe()\n",
    "\n",
    "    return desc_stats_numericas\n",
    "\n",
    "def main():\n",
    "    # Variáveis para análise descritiva\n",
    "    variaveis_para_analise = ['idade',  'tempo_em', 'sal_cli', 'tempo_res', 'qtd_parc', 'vlr_cpr', 'vlr_parc']\n",
    "\n",
    "    # Realizar análise descritiva\n",
    "    desc_stats_numericas = analise_descritiva(df, variaveis_para_analise)\n",
    "\n",
    "    # Imprimir resultados\n",
    "    print(\"Estatísticas Descritivas para Variáveis Numéricas:\")\n",
    "    print(desc_stats_numericas)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatísticas Descritivas para Variáveis Numéricas:\n",
      "              idade      tempo_em        sal_cli     tempo_res      qtd_parc  \\\n",
      "count  18000.000000  18000.000000   17998.000000  18000.000000  18000.000000   \n",
      "mean      42.896278    102.019278    1572.563755    160.166000      7.910333   \n",
      "std       13.470339     93.292373    1955.513545    141.291454      3.099112   \n",
      "min       18.000000      0.000000       0.010000      0.000000      1.000000   \n",
      "25%       32.000000     31.000000     722.082500     46.000000      6.000000   \n",
      "50%       41.000000     72.000000    1109.230000    120.000000      8.000000   \n",
      "75%       52.000000    144.000000    1791.922500    245.000000     12.000000   \n",
      "max       88.000000   1176.000000  158600.000000    960.000000     12.000000   \n",
      "\n",
      "            vlr_cpr      vlr_parc  \n",
      "count  18000.000000  18000.000000  \n",
      "mean     902.100776    205.121338  \n",
      "std      811.889030    174.457318  \n",
      "min      150.000000     40.860000  \n",
      "25%      400.000000    112.465000  \n",
      "50%      600.000000    159.770000  \n",
      "75%     1000.000000    239.002500  \n",
      "max    10000.000000   4328.370000  \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "e235881d-0135-45eb-89d4-fefa60545f56",
   "metadata": {
    "id": "e235881d-0135-45eb-89d4-fefa60545f56",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:15.992801Z",
     "start_time": "2024-04-17T12:40:15.978652Z"
    }
   },
   "source": [
    "#Como o menor salário é 0.01, vamos fazer um ajuste e colocar um valor mais factível como mínimo por exemplo R$ 250\n",
    "\n",
    "df['sal_cli'] = df['sal_cli'].apply(lambda x: 250 if pd.isnull(x) or x < 250 else x)\n",
    "\n",
    "# Criar nova variável dividindo 'vlr_parc' por 'sal_cli' - Comprometimento\n",
    "df['comprom'] = df['vlr_parc'] / df['sal_cli']\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "ff993ce6-d185-4967-907d-3c28232ff69e",
   "metadata": {
    "id": "ff993ce6-d185-4967-907d-3c28232ff69e",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:16.015333Z",
     "start_time": "2024-04-17T12:40:15.992801Z"
    }
   },
   "source": [
    "#amostra estratificada\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def criar_amostra_estratificada(df, variavel_resposta, tamanho_amostra, variaveis_preditoras):\n",
    "    X = df[variaveis_preditoras]\n",
    "    y = df[variavel_resposta]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tamanho_amostra, stratify=y, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Definição das variáveis preditoras para análise\n",
    "variaveis_para_analise = ['idade', 'qtd_com', 'tempo_em', 'sal_cli', 'tempo_res', 'qtd_parc', 'vlr_cpr', 'vlr_parc', 'tipo_cre','comprom']\n",
    "\n",
    "# Chamada da função para criar amostra estratificada\n",
    "X_train, X_test, y_train, y_test = criar_amostra_estratificada(df, 'tipo', 0.4, variaveis_para_analise)\n",
    "\n",
    "# Imprimir informações sobre a amostra\n",
    "print(\"\\nInformações sobre a amostra estratificada:\")\n",
    "print(\"Tamanho do conjunto de treino:\", len(X_train))\n",
    "print(\"Tamanho do conjunto de teste:\", len(X_test))\n",
    "\n",
    "\n",
    "# Calcular frequência da variável 'tipo' nas amostras de treino e teste\n",
    "frequencia_tipo_treino = y_train.value_counts()\n",
    "frequencia_tipo_teste = y_test.value_counts()\n",
    "\n",
    "# Imprimir frequência da variável 'tipo'\n",
    "print(\"Frequência da variável 'tipo' no conjunto de treino:\")\n",
    "print(frequencia_tipo_treino)\n",
    "\n",
    "print(\"\\nFrequência da variável 'tipo' no conjunto de teste:\")\n",
    "print(frequencia_tipo_teste)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informações sobre a amostra estratificada:\n",
      "Tamanho do conjunto de treino: 10800\n",
      "Tamanho do conjunto de teste: 7200\n",
      "Frequência da variável 'tipo' no conjunto de treino:\n",
      "tipo\n",
      "1    5400\n",
      "0    5400\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frequência da variável 'tipo' no conjunto de teste:\n",
      "tipo\n",
      "1    3600\n",
      "0    3600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "e1319211-2f42-4cd1-899b-dda76798bd59",
   "metadata": {
    "id": "e1319211-2f42-4cd1-899b-dda76798bd59",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:16.266122Z",
     "start_time": "2024-04-17T12:40:16.016348Z"
    }
   },
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Criar pipeline com modelo de regressão logística\n",
    "pipeline = Pipeline([\n",
    "    ('logistic_regression', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Treinar o modelo no pipeline usando os dados de treino\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Coeficientes do modelo de regressão logística\n",
    "coeficientes = pipeline.named_steps['logistic_regression'].coef_[0]\n",
    "\n",
    "# Intercepto do modelo de regressão logística\n",
    "intercepto = pipeline.named_steps['logistic_regression'].intercept_\n",
    "\n",
    "# Nomes das variáveis preditoras\n",
    "nomes_variaveis = X_train.columns.tolist()\n",
    "\n",
    "# Imprimir coeficientes associados a cada variável\n",
    "print(\"Coeficientes do modelo:\")\n",
    "for nome_variavel, coeficiente in zip(nomes_variaveis, coeficientes):\n",
    "    print(nome_variavel, \":\", coeficiente)\n",
    "\n",
    "# Imprimir intercepto do modelo\n",
    "print(\"\\nIntercepto do modelo:\", intercepto)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes do modelo:\n",
      "idade : 0.016312758022799623\n",
      "qtd_com : 0.8409731591401389\n",
      "tempo_em : 0.0015641375592017424\n",
      "sal_cli : 2.0057185859914225e-05\n",
      "tempo_res : 0.0001062054303791891\n",
      "qtd_parc : -0.23958372323792929\n",
      "vlr_cpr : 0.00020408853059889786\n",
      "vlr_parc : -0.0014172278393340533\n",
      "tipo_cre : 0.7491838002858225\n",
      "comprom : 0.005085309409442522\n",
      "\n",
      "Intercepto do modelo: [0.1015549]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gugat\\PycharmProjects\\PUC\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "cc14488f-f2d5-4132-9bd4-e9e7bd1475ff",
   "metadata": {
    "id": "cc14488f-f2d5-4132-9bd4-e9e7bd1475ff",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:16.288696Z",
     "start_time": "2024-04-17T12:40:16.266122Z"
    }
   },
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Prever as probabilidades das classes positivas para os dados de teste\n",
    "probabilidades_positivas = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular KS\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probabilidades_positivas)\n",
    "ks = max(tpr - fpr)\n",
    "\n",
    "# Calcular AUC (área sob a curva ROC)\n",
    "auc = roc_auc_score(y_test, probabilidades_positivas)\n",
    "\n",
    "# Calcular matriz de confusão\n",
    "previsoes = pipeline.predict(X_test)\n",
    "matriz_confusao = confusion_matrix(y_test, previsoes)\n",
    "\n",
    "# Calcular acurácia total\n",
    "acuracia_total = pipeline.score(X_test, y_test)\n",
    "\n",
    "# Imprimir métricas de avaliação\n",
    "print(\"KS:\", ks)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(matriz_confusao)\n",
    "print(\"Acurácia Total:\", acuracia_total)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS: 0.35944444444444446\n",
      "AUC: 0.7325966820987655\n",
      "Matriz de Confusão:\n",
      "[[2451 1149]\n",
      " [1202 2398]]\n",
      "Acurácia Total: 0.6734722222222222\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "64c3f0cf-009a-4f84-bfce-6d0a30e5076e",
   "metadata": {
    "id": "64c3f0cf-009a-4f84-bfce-6d0a30e5076e",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:30.689227Z",
     "start_time": "2024-04-17T12:40:16.288696Z"
    }
   },
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Criar modelo de redes neurais\n",
    "modelo_rede_neural = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "\n",
    "# Treinar o modelo nos dados de treino\n",
    "modelo_rede_neural.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo nos dados de teste\n",
    "acuracia_teste_rede_neural = modelo_rede_neural.score(X_test, y_test)\n",
    "\n",
    "# Imprimir acurácia do modelo nos dados de teste\n",
    "print(\"Acurácia do modelo de redes neurais nos dados de teste:\", acuracia_teste_rede_neural)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo de redes neurais nos dados de teste: 0.5322222222222223\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "46aa1955-c98d-40e5-bf50-93190d74fc31",
   "metadata": {
    "id": "46aa1955-c98d-40e5-bf50-93190d74fc31",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:30.763954Z",
     "start_time": "2024-04-17T12:40:30.689227Z"
    }
   },
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Prever as probabilidades das classes positivas para os dados de teste\n",
    "probabilidades_positivas_rede_neural = modelo_rede_neural.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular KS\n",
    "fpr_rede_neural, tpr_rede_neural, thresholds_rede_neural = roc_curve(y_test, probabilidades_positivas_rede_neural)\n",
    "ks_rede_neural = max(tpr_rede_neural - fpr_rede_neural)\n",
    "\n",
    "# Calcular AUC (área sob a curva ROC)\n",
    "auc_rede_neural = roc_auc_score(y_test, probabilidades_positivas_rede_neural)\n",
    "\n",
    "# Calcular matriz de confusão\n",
    "previsoes_rede_neural = modelo_rede_neural.predict(X_test)\n",
    "matriz_confusao_rede_neural = confusion_matrix(y_test, previsoes_rede_neural)\n",
    "\n",
    "# Calcular acurácia total\n",
    "acuracia_total_rede_neural = modelo_rede_neural.score(X_test, y_test)\n",
    "\n",
    "# Imprimir métricas de avaliação para o modelo de rede neural\n",
    "print(\"KS (Rede Neural):\", ks_rede_neural)\n",
    "print(\"AUC (Rede Neural):\", auc_rede_neural)\n",
    "print(\"Matriz de Confusão (Rede Neural):\")\n",
    "print(matriz_confusao_rede_neural)\n",
    "print(\"Acurácia Total (Rede Neural):\", acuracia_total_rede_neural)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS (Rede Neural): 0.2386111111111111\n",
      "AUC (Rede Neural): 0.6598560570987654\n",
      "Matriz de Confusão (Rede Neural):\n",
      "[[ 297 3303]\n",
      " [  65 3535]]\n",
      "Acurácia Total (Rede Neural): 0.5322222222222223\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "a471ab04-9c1a-465e-99ac-b554f0f1bda9",
   "metadata": {
    "id": "a471ab04-9c1a-465e-99ac-b554f0f1bda9",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:31.048717Z",
     "start_time": "2024-04-17T12:40:30.763954Z"
    }
   },
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Criar modelo de árvore de decisão\n",
    "modelo_arvore = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Treinar o modelo nos dados de treino\n",
    "modelo_arvore.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo nos dados de teste\n",
    "acuracia_teste_arvore = modelo_arvore.score(X_test, y_test)\n",
    "\n",
    "# Imprimir acurácia do modelo nos dados de teste\n",
    "print(\"Acurácia do modelo de árvore de decisão nos dados de teste:\", acuracia_teste_arvore)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo de árvore de decisão nos dados de teste: 0.6027777777777777\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "c3e02477-9f31-4f01-af78-56b87a9a96fb",
   "metadata": {
    "id": "c3e02477-9f31-4f01-af78-56b87a9a96fb",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:31.090105Z",
     "start_time": "2024-04-17T12:40:31.048717Z"
    }
   },
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Prever as probabilidades das classes positivas para os dados de teste\n",
    "probabilidades_positivas_arvore = modelo_arvore.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular KS\n",
    "fpr_arvore, tpr_arvore, thresholds_arvore = roc_curve(y_test, probabilidades_positivas_arvore)\n",
    "ks_arvore = max(tpr_arvore - fpr_arvore)\n",
    "\n",
    "# Calcular AUC (área sob a curva ROC)\n",
    "auc_arvore = roc_auc_score(y_test, probabilidades_positivas_arvore)\n",
    "\n",
    "# Calcular matriz de confusão\n",
    "previsoes_arvore = modelo_arvore.predict(X_test)\n",
    "matriz_confusao_arvore = confusion_matrix(y_test, previsoes_arvore)\n",
    "\n",
    "# Calcular acurácia total\n",
    "acuracia_total_arvore = modelo_arvore.score(X_test, y_test)\n",
    "\n",
    "# Imprimir métricas de avaliação para o modelo de árvore de decisão\n",
    "print(\"KS (Árvore de Decisão):\", ks_arvore)\n",
    "print(\"AUC (Árvore de Decisão):\", auc_arvore)\n",
    "print(\"Matriz de Confusão (Árvore de Decisão):\")\n",
    "print(matriz_confusao_arvore)\n",
    "print(\"Acurácia Total (Árvore de Decisão):\", acuracia_total_arvore)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS (Árvore de Decisão): 0.20555555555555555\n",
      "AUC (Árvore de Decisão): 0.6027777777777779\n",
      "Matriz de Confusão (Árvore de Decisão):\n",
      "[[2211 1389]\n",
      " [1471 2129]]\n",
      "Acurácia Total (Árvore de Decisão): 0.6027777777777777\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "05f58236-8eaf-43eb-8a83-958c09b5a694",
   "metadata": {
    "id": "05f58236-8eaf-43eb-8a83-958c09b5a694",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:35.322947Z",
     "start_time": "2024-04-17T12:40:31.090105Z"
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Criar modelo Random Forest\n",
    "modelo_random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Treinar o modelo nos dados de treino\n",
    "modelo_random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo nos dados de teste\n",
    "acuracia_teste_random_forest = modelo_random_forest.score(X_test, y_test)\n",
    "\n",
    "# Prever as probabilidades das classes positivas para os dados de teste\n",
    "probabilidades_positivas_random_forest = modelo_random_forest.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular KS\n",
    "fpr_random_forest, tpr_random_forest, thresholds_random_forest = roc_curve(y_test, probabilidades_positivas_random_forest)\n",
    "ks_random_forest = max(tpr_random_forest - fpr_random_forest)\n",
    "\n",
    "# Calcular AUC (área sob a curva ROC)\n",
    "auc_random_forest = roc_auc_score(y_test, probabilidades_positivas_random_forest)\n",
    "\n",
    "# Calcular matriz de confusão\n",
    "previsoes_random_forest = modelo_random_forest.predict(X_test)\n",
    "matriz_confusao_random_forest = confusion_matrix(y_test, previsoes_random_forest)\n",
    "\n",
    "# Calcular acurácia total\n",
    "acuracia_total_random_forest = modelo_random_forest.score(X_test, y_test)\n",
    "\n",
    "# Imprimir acurácia do modelo nos dados de teste\n",
    "print(\"Acurácia do modelo Random Forest nos dados de teste:\", acuracia_teste_random_forest)\n",
    "print(\"KS (Random Forest):\", ks_random_forest)\n",
    "print(\"AUC (Random Forest):\", auc_random_forest)\n",
    "print(\"Matriz de Confusão (Random Forest):\")\n",
    "print(matriz_confusao_random_forest)\n",
    "print(\"Acurácia Total (Random Forest):\", acuracia_total_random_forest)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo Random Forest nos dados de teste: 0.6556944444444445\n",
      "KS (Random Forest): 0.31166666666666665\n",
      "AUC (Random Forest): 0.7207170910493828\n",
      "Matriz de Confusão (Random Forest):\n",
      "[[2477 1123]\n",
      " [1356 2244]]\n",
      "Acurácia Total (Random Forest): 0.6556944444444445\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "cf969a08-202f-4f97-82fc-6042266e6a93",
   "metadata": {
    "id": "cf969a08-202f-4f97-82fc-6042266e6a93"
   },
   "source": [
    "Escorando uma base com o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "id": "2d65c797-3790-4afe-a82a-9e3279e80650",
   "metadata": {
    "id": "2d65c797-3790-4afe-a82a-9e3279e80650",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:46:26.382119Z",
     "start_time": "2024-04-17T12:46:25.503021Z"
    }
   },
   "source": [
    "# Carregar a nova base de clientes\n",
    "caminho_nova_base = 'Credito_escorar.xlsx'\n",
    "nova_base = pd.read_excel(caminho_nova_base)\n",
    "\n",
    "# Salvar os IDs dos clientes separadamente\n",
    "ids_clientes = nova_base['id']\n",
    "\n",
    "# Remover as colunas irrelevantes ('id', 'tipo') e reordenar as colunas para corresponder à ordem do modelo\n",
    "colunas_modelo = ['idade', 'qtd_com', 'tempo_em', 'sal_cli', 'tempo_res', 'qtd_parc', 'vlr_cpr', 'vlr_parc', 'tipo_cre']\n",
    "nova_base = nova_base[colunas_modelo]\n",
    "\n",
    "# Aplicar as transformações necessárias nas outras colunas\n",
    "nova_base['sal_cli'] = nova_base['sal_cli'].apply(lambda x: 250 if pd.isnull(x) or x < 250 else x)\n",
    "nova_base['comprom'] = nova_base['vlr_parc'] / nova_base['sal_cli']\n",
    "\n",
    "# Fazer previsões e obter probabilidades na nova base de clientes com as transformações aplicadas\n",
    "previsoes_probabilidades_nova_base = pipeline.predict_proba(nova_base)\n",
    "\n",
    "# Extrair as previsões e as probabilidades associadas\n",
    "probabilidades_nova_base = previsoes_probabilidades_nova_base[:, 1]  # Probabilidades para a classe positiva (ou 1)\n",
    "\n",
    "# Adicionar as previsões e as probabilidades como novas colunas na nova base de clientes\n",
    "nova_base['probabilidade'] = probabilidades_nova_base\n",
    "\n",
    "# Juntar os IDs dos clientes de volta à nova base de clientes\n",
    "nova_base['id'] = ids_clientes\n",
    "\n",
    "# Salvar a nova base de clientes com as previsões\n",
    "caminho_saida = 'Credito_escorada.xlsx'\n",
    "nova_base.to_excel(caminho_saida, index=False)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "9f9b3514-8ddc-4448-b78c-a1bab33137cf",
   "metadata": {
    "id": "9f9b3514-8ddc-4448-b78c-a1bab33137cf",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:46:34.344365Z",
     "start_time": "2024-04-17T12:46:33.322435Z"
    }
   },
   "source": [
    "nova_base = pd.read_excel(caminho_nova_base)\n",
    "\n",
    "# Salvar os IDs dos clientes separadamente\n",
    "ids_clientes = nova_base['id']\n",
    "\n",
    "# Remover as colunas irrelevantes ('id', 'tipo') e reordenar as colunas para corresponder à ordem do modelo\n",
    "colunas_modelo = ['idade',  'qtd_com', 'tempo_em', 'sal_cli', 'tempo_res', 'qtd_parc', 'vlr_cpr', 'vlr_parc', 'tipo_cre']\n",
    "nova_base = nova_base[colunas_modelo]\n",
    "\n",
    "# Aplicar as transformações necessárias nas outras colunas\n",
    "nova_base['sal_cli'] = nova_base['sal_cli'].apply(lambda x: 250 if pd.isnull(x) or x < 250 else x)\n",
    "nova_base['comprom'] = nova_base['vlr_parc'] / nova_base['sal_cli']\n",
    "\n",
    "# Fazer previsões e obter probabilidades na nova base de clientes com as transformações aplicadas\n",
    "previsoes_probabilidades_nova_base = modelo_random_forest.predict_proba(nova_base)\n",
    "\n",
    "# Extrair as previsões e as probabilidades associadas\n",
    "probabilidades_nova_base = previsoes_probabilidades_nova_base[:, 1]  # Probabilidades para a classe positiva (ou 1)\n",
    "\n",
    "# Adicionar as previsões e as probabilidades como novas colunas na nova base de clientes\n",
    "nova_base['probabilidade'] = probabilidades_nova_base\n",
    "\n",
    "# Juntar os IDs dos clientes de volta à nova base de clientes\n",
    "nova_base['id'] = ids_clientes\n",
    "\n",
    "\n",
    "# Salvar a nova base de clientes com as previsões\n",
    "caminho_saida = 'Credito_escorar.xlsx'\n",
    "nova_base.to_excel(caminho_saida, index=False)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "cf192b99-8c2c-4fe1-a08e-539d66cddbf0",
   "metadata": {
    "id": "cf192b99-8c2c-4fe1-a08e-539d66cddbf0",
    "ExecuteTime": {
     "end_time": "2024-04-17T12:40:35.489069Z",
     "start_time": "2024-04-17T12:40:35.489069Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
